Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>