Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Je suis en train de m'organiser pour aller au Capitole du Libre, encore deux trois trucs à régler avant d'être sûr de pouvoir venir.
Si je suis présent, est ce que sur le weekend tu seras dispo pour qu'on prenne le temps de faire un atelier pour échanger sur la conception et l'interfaçage de la constellation d'auto-hébergeur ?

A bientôt,
Robin

Réponse générée : 
Bonjour Robin,

Super de pouvoir se rencontrer au Capitole du Libre !

Je serai sur le stand de FooPGP, on y présentera Sagittarius et le ẑen

On se voit ce week end

Fred
Contenu de l'email : 
Salut Fred,

C'était sympa de se rencontrer IRL !

Je te propose une suite à nos échanges :

- Le point départ c'est une volonté commune d'expérimenter sur des LLM open-source, avec des machines auto-hébergées.
- Pour les accès serveur on s'organise comment ?
- Je peux contribuer via le système d'abonnement à 15-20e par mois.
- Ton expertise c'est l'infrastructure et les systèmes décentralisés ?

De mon côté c'est les interactions humain-réseau de neurone que je souhaite explorer.
Je te partage la maquette de mon gestionnaire de prompt ;)

[promptyx-ui-0.1.png]

A bientôt,
Robin

Réponse générée : 
Salut Robin,

Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la 
campagne.
Me voila de retour à Toulouse, au G1FabLab.

Le 22/11/2024 à 16:10, Robin Couret a écrit :
> Salut Fred,
>
> C'était sympa de se rencontrer IRL !
Ouaih! Cool de s'être rencontré au Capitole du Libre.
>
> Je te propose une suite à nos échanges :
>
>   * Le point départ c'est une volonté commune d'expérimenter sur des
>     LLM open-source, avec des machines auto-hébergées.
>
Oui! C'est ce qu'on va expérimenter ensemble ;)
En ajoutant l'utilisation de jetons pour en gérer l'accès et en partager 
les ressources...
J'en cause sur le blog de https://www.copylaradio.com/
>
>   * Pour les accès serveur on s'organise comment ?
>
On pourra utiliser ssh en visio pour commencer. Et puis détailler ce 
qu'il te faut comme
ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>
>   * Je peux contribuer via le système d'abonnement à 15-20e par mois.
>
Tu peux prendre un forfait "COOL",
https://opencollective.com/uplanet-zero/contribute/
ou cotiser à l'Infrastructure "G1FabLab Toulouse"
https://opencollective.com/monnaie-libre

>   * Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>
Je touche un peu à tout, mais oui, j'adore les système résilients 
autonomes ;)

>  *
>
>
> De mon côté c'est les interactions humain-réseau de neurone que je 
> souhaite explorer.
> Je te partage la maquette de mon gestionnaire de prompt ;)
Tu me diras ce qu'il faut pout exécuter son code ?
API ollama, librairies python, docker ou autre...

>
> promptyx-ui-0.1.png
>
> A bientôt,
> RobinContenu de l'email : 
Salut, salut,

Trop bien, je bouge en Ardèche demain moi :)

J'ai fait un support, fait rapidement avec l'inspi de Jah ^^
On se fait un appel en décembre pour les accès + discussion support ?

A bientôt,
Rob

[Support1Saggitarius.png][Support2Sadgitarius.png]

Envoyé avec la messagerie sécurisée [Proton Mail.](https://proton.me/mail/home)

Le jeudi 28 novembre 2024 à 21:34, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin,
>
> Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la campagne.
> Me voila de retour à Toulouse, au G1FabLab.
>
> Le 22/11/2024 à 16:10, Robin Couret a écrit :
>
>> Salut Fred,
>>
>> C'était sympa de se rencontrer IRL !
>
> Ouaih! Cool de s'être rencontré au Capitole du Libre.
>
>> Je te propose une suite à nos échanges :
>>
>> - Le point départ c'est une volonté commune d'expérimenter sur des LLM open-source, avec des machines auto-hébergées.
>
> Oui! C'est ce qu'on va expérimenter ensemble ;)
> En ajoutant l'utilisation de jetons pour en gérer l'accès et en partager les ressources...
> J'en cause sur le blog de https://www.copylaradio.com/
>
>> - Pour les accès serveur on s'organise comment ?
>
> On pourra utiliser ssh en visio pour commencer. Et puis détailler ce qu'il te faut comme
> ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>
>> - Je peux contribuer via le système d'abonnement à 15-20e par mois.
>
> Tu peux prendre un forfait "COOL",
> https://opencollective.com/uplanet-zero/contribute/
> ou cotiser à l'Infrastructure "G1FabLab Toulouse"
> https://opencollective.com/monnaie-libre
>
>> - Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>
> Je touche un peu à tout, mais oui, j'adore les système résilients autonomes ;)
>
>> -
>>
>> De mon côté c'est les interactions humain-réseau de neurone que je souhaite explorer.
>> Je te partage la maquette de mon gestionnaire de prompt ;)
>
> Tu me diras ce qu'il faut pout exécuter son code ?
> API ollama, librairies python, docker ou autre...
>
>> [promptyx-ui-0.1.png]
>>
>> A bientôt,
>> Robin

Réponse générée : 
Je t'ai envoyé un lien si tu veux participer à la rédaction d'articles 
sur www.copylaradio.com

Le 28/11/2024 à 22:02, Robin Couret a écrit :
> Salut, salut,
>
> Trop bien, je bouge en Ardèche demain moi :)
>
> J'ai fait un support, fait rapidement avec l'inspi de Jah ^^
> On se fait un appel en décembre pour les accès + discussion support ?
>
> A bientôt,
> Rob
>
> Support1Saggitarius.pngSupport2Sadgitarius.png
>
> Envoyé avec la messagerie sécurisée Proton Mail. 
> <https://proton.me/mail/home>
>
> Le jeudi 28 novembre 2024 à 21:34, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin,
>>
>> Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la 
>> campagne.
>> Me voila de retour à Toulouse, au G1FabLab.
>>
>> Le 22/11/2024 à 16:10, Robin Couret a écrit :
>>> Salut Fred,
>>>
>>> C'était sympa de se rencontrer IRL !
>> Ouaih! Cool de s'être rencontré au Capitole du Libre.
>>>
>>> Je te propose une suite à nos échanges :
>>>
>>>   * Le point départ c'est une volonté commune d'expérimenter sur des
>>>     LLM open-source, avec des machines auto-hébergées.
>>>
>> Oui! C'est ce qu'on va expérimenter ensemble ;)
>> En ajoutant l'utilisation de jetons pour en gérer l'accès et en 
>> partager les ressources...
>> J'en cause sur le blog de https://www.copylaradio.com/
>>>
>>>   * Pour les accès serveur on s'organise comment ?
>>>
>> On pourra utiliser ssh en visio pour commencer. Et puis détailler ce 
>> qu'il te faut comme
>> ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>>>
>>>   * Je peux contribuer via le système d'abonnement à 15-20e par mois.
>>>
>> Tu peux prendre un forfait "COOL",
>> https://opencollective.com/uplanet-zero/contribute/
>> ou cotiser à l'Infrastructure "G1FabLab Toulouse"
>> https://opencollective.com/monnaie-libre
>>
>>>   * Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>>>
>> Je touche un peu à tout, mais oui, j'adore les système résilients 
>> autonomes ;)
>>
>>>  *
>>>
>>>
>>> De mon côté c'est les interactions humain-réseau de neurone que je 
>>> souhaite explorer.
>>> Je te partage la maquette de mon gestionnaire de prompt ;)
>> Tu me diras ce qu'il faut pout exécuter son code ?
>> API ollama, librairies python, docker ou autre...
>>
>>>
>>> promptyx-ui-0.1.png
>>>
>>> A bientôt,
>>> Robin
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Je suis en train de m'organiser pour aller au Capitole du Libre, encore deux trois trucs à régler avant d'être sûr de pouvoir venir.
Si je suis présent, est ce que sur le weekend tu seras dispo pour qu'on prenne le temps de faire un atelier pour échanger sur la conception et l'interfaçage de la constellation d'auto-hébergeur ?

A bientôt,
Robin

Réponse générée : 
Bonjour Robin,

Super de pouvoir se rencontrer au Capitole du Libre !

Je serai sur le stand de FooPGP, on y présentera Sagittarius et le ẑen

On se voit ce week end

Fred
Contenu de l'email : 
Salut Fred,

C'était sympa de se rencontrer IRL !

Je te propose une suite à nos échanges :

- Le point départ c'est une volonté commune d'expérimenter sur des LLM open-source, avec des machines auto-hébergées.
- Pour les accès serveur on s'organise comment ?
- Je peux contribuer via le système d'abonnement à 15-20e par mois.
- Ton expertise c'est l'infrastructure et les systèmes décentralisés ?

De mon côté c'est les interactions humain-réseau de neurone que je souhaite explorer.
Je te partage la maquette de mon gestionnaire de prompt ;)

[promptyx-ui-0.1.png]

A bientôt,
Robin

Réponse générée : 
Salut Robin,

Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la 
campagne.
Me voila de retour à Toulouse, au G1FabLab.

Le 22/11/2024 à 16:10, Robin Couret a écrit :
> Salut Fred,
>
> C'était sympa de se rencontrer IRL !
Ouaih! Cool de s'être rencontré au Capitole du Libre.
>
> Je te propose une suite à nos échanges :
>
>   * Le point départ c'est une volonté commune d'expérimenter sur des
>     LLM open-source, avec des machines auto-hébergées.
>
Oui! C'est ce qu'on va expérimenter ensemble ;)
En ajoutant l'utilisation de jetons pour en gérer l'accès et en partager 
les ressources...
J'en cause sur le blog de https://www.copylaradio.com/
>
>   * Pour les accès serveur on s'organise comment ?
>
On pourra utiliser ssh en visio pour commencer. Et puis détailler ce 
qu'il te faut comme
ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>
>   * Je peux contribuer via le système d'abonnement à 15-20e par mois.
>
Tu peux prendre un forfait "COOL",
https://opencollective.com/uplanet-zero/contribute/
ou cotiser à l'Infrastructure "G1FabLab Toulouse"
https://opencollective.com/monnaie-libre

>   * Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>
Je touche un peu à tout, mais oui, j'adore les système résilients 
autonomes ;)

>  *
>
>
> De mon côté c'est les interactions humain-réseau de neurone que je 
> souhaite explorer.
> Je te partage la maquette de mon gestionnaire de prompt ;)
Tu me diras ce qu'il faut pout exécuter son code ?
API ollama, librairies python, docker ou autre...

>
> promptyx-ui-0.1.png
>
> A bientôt,
> RobinContenu de l'email : 
Salut, salut,

Trop bien, je bouge en Ardèche demain moi :)

J'ai fait un support, fait rapidement avec l'inspi de Jah ^^
On se fait un appel en décembre pour les accès + discussion support ?

A bientôt,
Rob

[Support1Saggitarius.png][Support2Sadgitarius.png]

Envoyé avec la messagerie sécurisée [Proton Mail.](https://proton.me/mail/home)

Le jeudi 28 novembre 2024 à 21:34, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin,
>
> Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la campagne.
> Me voila de retour à Toulouse, au G1FabLab.
>
> Le 22/11/2024 à 16:10, Robin Couret a écrit :
>
>> Salut Fred,
>>
>> C'était sympa de se rencontrer IRL !
>
> Ouaih! Cool de s'être rencontré au Capitole du Libre.
>
>> Je te propose une suite à nos échanges :
>>
>> - Le point départ c'est une volonté commune d'expérimenter sur des LLM open-source, avec des machines auto-hébergées.
>
> Oui! C'est ce qu'on va expérimenter ensemble ;)
> En ajoutant l'utilisation de jetons pour en gérer l'accès et en partager les ressources...
> J'en cause sur le blog de https://www.copylaradio.com/
>
>> - Pour les accès serveur on s'organise comment ?
>
> On pourra utiliser ssh en visio pour commencer. Et puis détailler ce qu'il te faut comme
> ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>
>> - Je peux contribuer via le système d'abonnement à 15-20e par mois.
>
> Tu peux prendre un forfait "COOL",
> https://opencollective.com/uplanet-zero/contribute/
> ou cotiser à l'Infrastructure "G1FabLab Toulouse"
> https://opencollective.com/monnaie-libre
>
>> - Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>
> Je touche un peu à tout, mais oui, j'adore les système résilients autonomes ;)
>
>> -
>>
>> De mon côté c'est les interactions humain-réseau de neurone que je souhaite explorer.
>> Je te partage la maquette de mon gestionnaire de prompt ;)
>
> Tu me diras ce qu'il faut pout exécuter son code ?
> API ollama, librairies python, docker ou autre...
>
>> [promptyx-ui-0.1.png]
>>
>> A bientôt,
>> Robin

Réponse générée : 
Je t'ai envoyé un lien si tu veux participer à la rédaction d'articles 
sur www.copylaradio.com

Le 28/11/2024 à 22:02, Robin Couret a écrit :
> Salut, salut,
>
> Trop bien, je bouge en Ardèche demain moi :)
>
> J'ai fait un support, fait rapidement avec l'inspi de Jah ^^
> On se fait un appel en décembre pour les accès + discussion support ?
>
> A bientôt,
> Rob
>
> Support1Saggitarius.pngSupport2Sadgitarius.png
>
> Envoyé avec la messagerie sécurisée Proton Mail. 
> <https://proton.me/mail/home>
>
> Le jeudi 28 novembre 2024 à 21:34, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin,
>>
>> Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la 
>> campagne.
>> Me voila de retour à Toulouse, au G1FabLab.
>>
>> Le 22/11/2024 à 16:10, Robin Couret a écrit :
>>> Salut Fred,
>>>
>>> C'était sympa de se rencontrer IRL !
>> Ouaih! Cool de s'être rencontré au Capitole du Libre.
>>>
>>> Je te propose une suite à nos échanges :
>>>
>>>   * Le point départ c'est une volonté commune d'expérimenter sur des
>>>     LLM open-source, avec des machines auto-hébergées.
>>>
>> Oui! C'est ce qu'on va expérimenter ensemble ;)
>> En ajoutant l'utilisation de jetons pour en gérer l'accès et en 
>> partager les ressources...
>> J'en cause sur le blog de https://www.copylaradio.com/
>>>
>>>   * Pour les accès serveur on s'organise comment ?
>>>
>> On pourra utiliser ssh en visio pour commencer. Et puis détailler ce 
>> qu'il te faut comme
>> ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>>>
>>>   * Je peux contribuer via le système d'abonnement à 15-20e par mois.
>>>
>> Tu peux prendre un forfait "COOL",
>> https://opencollective.com/uplanet-zero/contribute/
>> ou cotiser à l'Infrastructure "G1FabLab Toulouse"
>> https://opencollective.com/monnaie-libre
>>
>>>   * Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>>>
>> Je touche un peu à tout, mais oui, j'adore les système résilients 
>> autonomes ;)
>>
>>>  *
>>>
>>>
>>> De mon côté c'est les interactions humain-réseau de neurone que je 
>>> souhaite explorer.
>>> Je te partage la maquette de mon gestionnaire de prompt ;)
>> Tu me diras ce qu'il faut pout exécuter son code ?
>> API ollama, librairies python, docker ou autre...
>>
>>>
>>> promptyx-ui-0.1.png
>>>
>>> A bientôt,
>>> Robin
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Je suis en train de m'organiser pour aller au Capitole du Libre, encore deux trois trucs à régler avant d'être sûr de pouvoir venir.
Si je suis présent, est ce que sur le weekend tu seras dispo pour qu'on prenne le temps de faire un atelier pour échanger sur la conception et l'interfaçage de la constellation d'auto-hébergeur ?

A bientôt,
Robin

Réponse générée : 
Bonjour Robin,

Super de pouvoir se rencontrer au Capitole du Libre !

Je serai sur le stand de FooPGP, on y présentera Sagittarius et le ẑen

On se voit ce week end

Fred
Contenu de l'email : 
Salut Fred,

C'était sympa de se rencontrer IRL !

Je te propose une suite à nos échanges :

- Le point départ c'est une volonté commune d'expérimenter sur des LLM open-source, avec des machines auto-hébergées.
- Pour les accès serveur on s'organise comment ?
- Je peux contribuer via le système d'abonnement à 15-20e par mois.
- Ton expertise c'est l'infrastructure et les systèmes décentralisés ?

De mon côté c'est les interactions humain-réseau de neurone que je souhaite explorer.
Je te partage la maquette de mon gestionnaire de prompt ;)

[promptyx-ui-0.1.png]

A bientôt,
Robin

Réponse générée : 
Salut Robin,

Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la 
campagne.
Me voila de retour à Toulouse, au G1FabLab.

Le 22/11/2024 à 16:10, Robin Couret a écrit :
> Salut Fred,
>
> C'était sympa de se rencontrer IRL !
Ouaih! Cool de s'être rencontré au Capitole du Libre.
>
> Je te propose une suite à nos échanges :
>
>   * Le point départ c'est une volonté commune d'expérimenter sur des
>     LLM open-source, avec des machines auto-hébergées.
>
Oui! C'est ce qu'on va expérimenter ensemble ;)
En ajoutant l'utilisation de jetons pour en gérer l'accès et en partager 
les ressources...
J'en cause sur le blog de https://www.copylaradio.com/
>
>   * Pour les accès serveur on s'organise comment ?
>
On pourra utiliser ssh en visio pour commencer. Et puis détailler ce 
qu'il te faut comme
ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>
>   * Je peux contribuer via le système d'abonnement à 15-20e par mois.
>
Tu peux prendre un forfait "COOL",
https://opencollective.com/uplanet-zero/contribute/
ou cotiser à l'Infrastructure "G1FabLab Toulouse"
https://opencollective.com/monnaie-libre

>   * Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>
Je touche un peu à tout, mais oui, j'adore les système résilients 
autonomes ;)

>  *
>
>
> De mon côté c'est les interactions humain-réseau de neurone que je 
> souhaite explorer.
> Je te partage la maquette de mon gestionnaire de prompt ;)
Tu me diras ce qu'il faut pout exécuter son code ?
API ollama, librairies python, docker ou autre...

>
> promptyx-ui-0.1.png
>
> A bientôt,
> RobinContenu de l'email : 
Salut, salut,

Trop bien, je bouge en Ardèche demain moi :)

J'ai fait un support, fait rapidement avec l'inspi de Jah ^^
On se fait un appel en décembre pour les accès + discussion support ?

A bientôt,
Rob

[Support1Saggitarius.png][Support2Sadgitarius.png]

Envoyé avec la messagerie sécurisée [Proton Mail.](https://proton.me/mail/home)

Le jeudi 28 novembre 2024 à 21:34, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin,
>
> Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la campagne.
> Me voila de retour à Toulouse, au G1FabLab.
>
> Le 22/11/2024 à 16:10, Robin Couret a écrit :
>
>> Salut Fred,
>>
>> C'était sympa de se rencontrer IRL !
>
> Ouaih! Cool de s'être rencontré au Capitole du Libre.
>
>> Je te propose une suite à nos échanges :
>>
>> - Le point départ c'est une volonté commune d'expérimenter sur des LLM open-source, avec des machines auto-hébergées.
>
> Oui! C'est ce qu'on va expérimenter ensemble ;)
> En ajoutant l'utilisation de jetons pour en gérer l'accès et en partager les ressources...
> J'en cause sur le blog de https://www.copylaradio.com/
>
>> - Pour les accès serveur on s'organise comment ?
>
> On pourra utiliser ssh en visio pour commencer. Et puis détailler ce qu'il te faut comme
> ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>
>> - Je peux contribuer via le système d'abonnement à 15-20e par mois.
>
> Tu peux prendre un forfait "COOL",
> https://opencollective.com/uplanet-zero/contribute/
> ou cotiser à l'Infrastructure "G1FabLab Toulouse"
> https://opencollective.com/monnaie-libre
>
>> - Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>
> Je touche un peu à tout, mais oui, j'adore les système résilients autonomes ;)
>
>> -
>>
>> De mon côté c'est les interactions humain-réseau de neurone que je souhaite explorer.
>> Je te partage la maquette de mon gestionnaire de prompt ;)
>
> Tu me diras ce qu'il faut pout exécuter son code ?
> API ollama, librairies python, docker ou autre...
>
>> [promptyx-ui-0.1.png]
>>
>> A bientôt,
>> Robin

Réponse générée : 
Je t'ai envoyé un lien si tu veux participer à la rédaction d'articles 
sur www.copylaradio.com

Le 28/11/2024 à 22:02, Robin Couret a écrit :
> Salut, salut,
>
> Trop bien, je bouge en Ardèche demain moi :)
>
> J'ai fait un support, fait rapidement avec l'inspi de Jah ^^
> On se fait un appel en décembre pour les accès + discussion support ?
>
> A bientôt,
> Rob
>
> Support1Saggitarius.pngSupport2Sadgitarius.png
>
> Envoyé avec la messagerie sécurisée Proton Mail. 
> <https://proton.me/mail/home>
>
> Le jeudi 28 novembre 2024 à 21:34, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin,
>>
>> Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la 
>> campagne.
>> Me voila de retour à Toulouse, au G1FabLab.
>>
>> Le 22/11/2024 à 16:10, Robin Couret a écrit :
>>> Salut Fred,
>>>
>>> C'était sympa de se rencontrer IRL !
>> Ouaih! Cool de s'être rencontré au Capitole du Libre.
>>>
>>> Je te propose une suite à nos échanges :
>>>
>>>   * Le point départ c'est une volonté commune d'expérimenter sur des
>>>     LLM open-source, avec des machines auto-hébergées.
>>>
>> Oui! C'est ce qu'on va expérimenter ensemble ;)
>> En ajoutant l'utilisation de jetons pour en gérer l'accès et en 
>> partager les ressources...
>> J'en cause sur le blog de https://www.copylaradio.com/
>>>
>>>   * Pour les accès serveur on s'organise comment ?
>>>
>> On pourra utiliser ssh en visio pour commencer. Et puis détailler ce 
>> qu'il te faut comme
>> ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>>>
>>>   * Je peux contribuer via le système d'abonnement à 15-20e par mois.
>>>
>> Tu peux prendre un forfait "COOL",
>> https://opencollective.com/uplanet-zero/contribute/
>> ou cotiser à l'Infrastructure "G1FabLab Toulouse"
>> https://opencollective.com/monnaie-libre
>>
>>>   * Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>>>
>> Je touche un peu à tout, mais oui, j'adore les système résilients 
>> autonomes ;)
>>
>>>  *
>>>
>>>
>>> De mon côté c'est les interactions humain-réseau de neurone que je 
>>> souhaite explorer.
>>> Je te partage la maquette de mon gestionnaire de prompt ;)
>> Tu me diras ce qu'il faut pout exécuter son code ?
>> API ollama, librairies python, docker ou autre...
>>
>>>
>>> promptyx-ui-0.1.png
>>>
>>> A bientôt,
>>> Robin
>Contenu de l'email : 
Salut Fred,

Excellent si t'as de la puissance de calcul sur une architecture décentralisée. Je sais pas si t'as étudié des projets comme bittensor ? Sinon tu fais tourner quel modèle de llm ? Je me rends pas compte de la puissance de calcul nécessaire pour exécuter des requêtes sur un modèle riche.

De mon côté, je développe un outil assez simple dont le but est d’interagir avec une base de connaissance de prompts. Par exemple, dans le développement web, je suis amené à utiliser régulièrement des prompts quasi similaires et plutôt que les copier/coller dans un chat je voudrais pouvoir les utiliser de manière plus automatique. J'ai quelques autres idées d'usage. C'est un petit projet que je fais sur mon temps libre, je viens juste de commencer : https://github.com/Nojann/Promptyx

Fin de semaine prochaine, en soirée, tu serais dispo pour échanger autour de ces questions ?

Bonne journée !
Robin
Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin
>
> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en essaim (WoT PGP)
> ça va permettre de proposer des services NextCloud et IA en "co-propriété / location"
> Dis m'en plus sur ce que tu développes... et faisons une visio pour en discuster directement...
>
> A+
>
> Fred
>
> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>
>> Bonjour Frédéric,
>>
>> Je te contacte ici pour échanger sur des solutions de LLM auto-hébergées. Je fais pas parti de la TDC, je suis simplement curieux de duniter et je passe de temps en temps sur le forum. J’ai vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait en discuter par appel ou visio plus dans le détail ? Je développe un outil basé sur une API de LLM et je pourrais être intéressé pour me connecter sur une solution auto-hébergée. N’hésite pas à me répondre directement à couret.robin@protonmail.com.
>>
>> Bonne journée,
>> Robin

Réponse générée : 
Salut

Le 11/10/2024 à 10:59, Robin Couret a écrit :
> Salut Fred,
>
> Excellent si t'as de la puissance de calcul sur une architecture 
> décentralisée. Je sais pas si t'as étudié des projets comme bittensor ?

Je ne connaissais pas "bittensor", mais ça ressemble fortement à ce que 
j'expérimente sur le réseau "Astroport.ONE" en attribuant des wallets 
aux nodes, en utilisant IPFS comme stockage et les transactions comme 
API (au travers du champs commentaire).
En gros, ça permet au client d'écrire sa commande sur le billet qui paye 
le cuisinier qui renvoi le plat sur une pièce de 10cts ;)
J'en profite pour démarrer une toile de confiance technique qui relie 
les noeuds de l'essaim par la WoT G1 et/ou PGP

> Sinon tu fais tourner quel modèle de llm ?

Sagittarius, la machine qui est au G1FabLab a 64Go de RAM et 24Go de 
VRAM (RTX3090), les 2 autres noeuds ont "32Go/8Go".
ça permet de lancer des modèles "triple agents" comme 
"deepseek-coder-v2", ou "mixtral" avec un grand contexte... Mais 
attention au "memory overlow"...
L'avantage de l'essaime est qu'on peut réaliser un système multiagent 
sur différents noeuds...
j'ai essayé plusieurs modèles https://ollama.com/library
Là j'utilise llama3.2 pour mettre au point un système de "réponse email 
automatique", en test sur cette BAL ;)

> Je me rends pas compte de la puissance de calcul nécessaire pour 
> exécuter des requêtes sur un modèle riche.
On peut faire des choses plutot sympa dès qu'on a 8Go de VRAM... et 
qu'on ajuste bien le batch processing...
A titre de comparaison, je te laisse regarder
https://www.copylaradio.com/blog/blog-1/post/comparaison-des-gpus-nvidia-socs-apple-et-offres-cloud-ia-pour-lia-llm-101
>
> De mon côté, je développe un outil assez simple dont le but est 
> d’interagir avec une base de connaissance de prompts. Par exemple, 
> dans le développement web, je suis amené à utiliser régulièrement des 
> prompts quasi similaires et plutôt que les copier/coller dans un chat 
> je voudrais pouvoir les utiliser de manière plus automatique. J'ai 
> quelques autres idées d'usage. C'est un petit projet que je fais sur 
> mon temps libre, je viens juste de commencer : 
> https://github.com/Nojann/Promptyx
C'est une bonne idée... Les IA ont besoin de révéler "leurs 
personnalités" par de bons prompts.
Tu connais "fabric"? Je l'ai forké pour traduire ses prompts en 
français... https://github.com/papiche/fabric-fr mais j'ai pas eu le 
temps de m'en occuper ;)

Ensuite, quand le "prompt est bon", au lieu de rester comme embedding, 
on peut "forger" un nouveau modèle
https://www.copylaradio.com/blog/blog-1/post/torchtune-107 (pas essayé 
encore)

>
> Fin de semaine prochaine, en soirée, tu serais dispo pour échanger 
> autour de ces questions ?
oui, dispo...
L'agenda est là 
https://cloud.copylaradio.com/apps/calendar/p/gzjZRcAtFBrYciDN/dayGridMonth/now
Tu peux choisir ta date 
https://cloud.copylaradio.com/index.php/apps/appointments/pub/qPrkBHv9Ros%3D/form
>
> Bonne journée !
> Robin

Bon week end, a+

Fred

>
> Le vendredi 11 octobre 2024 à 02:16, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin
>>
>> Effectivement, j'ai commencé à mettre en ligne qq "PC Gamer" en 
>> essaim (WoT PGP)
>> ça va permettre de proposer des services NextCloud et IA en 
>> "co-propriété / location"
>> Dis m'en plus sur ce que tu développes... et faisons une visio pour 
>> en discuster directement...
>>
>> A+
>>
>> Fred
>>
>> Le 6 oct., 13:05, https://forum.duniter.org/t/auto-hegergement/12542 :
>>>
>>> Bonjour Frédéric,
>>>
>>> Je te contacte ici pour échanger sur des solutions de LLM 
>>> auto-hébergées. Je fais pas parti de la TDC, je suis simplement 
>>> curieux de duniter et je passe de temps en temps sur le forum. J’ai 
>>> vu que tu faisais de l’auto hébergement d’IA. Est ce qu’on pourrait 
>>> en discuter par appel ou visio plus dans le détail ? Je développe un 
>>> outil basé sur une API de LLM et je pourrais être intéressé pour me 
>>> connecter sur une solution auto-hébergée. N’hésite pas à me répondre 
>>> directement à couret.robin@protonmail.com.
>>>
>>> Bonne journée,
>>> Robin
>>>
>Contenu de l'email : 
Salut Fred,

Je suis en train de m'organiser pour aller au Capitole du Libre, encore deux trois trucs à régler avant d'être sûr de pouvoir venir.
Si je suis présent, est ce que sur le weekend tu seras dispo pour qu'on prenne le temps de faire un atelier pour échanger sur la conception et l'interfaçage de la constellation d'auto-hébergeur ?

A bientôt,
Robin

Réponse générée : 
Bonjour Robin,

Super de pouvoir se rencontrer au Capitole du Libre !

Je serai sur le stand de FooPGP, on y présentera Sagittarius et le ẑen

On se voit ce week end

Fred
Contenu de l'email : 
Salut Fred,

C'était sympa de se rencontrer IRL !

Je te propose une suite à nos échanges :

- Le point départ c'est une volonté commune d'expérimenter sur des LLM open-source, avec des machines auto-hébergées.
- Pour les accès serveur on s'organise comment ?
- Je peux contribuer via le système d'abonnement à 15-20e par mois.
- Ton expertise c'est l'infrastructure et les systèmes décentralisés ?

De mon côté c'est les interactions humain-réseau de neurone que je souhaite explorer.
Je te partage la maquette de mon gestionnaire de prompt ;)

[promptyx-ui-0.1.png]

A bientôt,
Robin

Réponse générée : 
Salut Robin,

Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la 
campagne.
Me voila de retour à Toulouse, au G1FabLab.

Le 22/11/2024 à 16:10, Robin Couret a écrit :
> Salut Fred,
>
> C'était sympa de se rencontrer IRL !
Ouaih! Cool de s'être rencontré au Capitole du Libre.
>
> Je te propose une suite à nos échanges :
>
>   * Le point départ c'est une volonté commune d'expérimenter sur des
>     LLM open-source, avec des machines auto-hébergées.
>
Oui! C'est ce qu'on va expérimenter ensemble ;)
En ajoutant l'utilisation de jetons pour en gérer l'accès et en partager 
les ressources...
J'en cause sur le blog de https://www.copylaradio.com/
>
>   * Pour les accès serveur on s'organise comment ?
>
On pourra utiliser ssh en visio pour commencer. Et puis détailler ce 
qu'il te faut comme
ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>
>   * Je peux contribuer via le système d'abonnement à 15-20e par mois.
>
Tu peux prendre un forfait "COOL",
https://opencollective.com/uplanet-zero/contribute/
ou cotiser à l'Infrastructure "G1FabLab Toulouse"
https://opencollective.com/monnaie-libre

>   * Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>
Je touche un peu à tout, mais oui, j'adore les système résilients 
autonomes ;)

>  *
>
>
> De mon côté c'est les interactions humain-réseau de neurone que je 
> souhaite explorer.
> Je te partage la maquette de mon gestionnaire de prompt ;)
Tu me diras ce qu'il faut pout exécuter son code ?
API ollama, librairies python, docker ou autre...

>
> promptyx-ui-0.1.png
>
> A bientôt,
> RobinContenu de l'email : 
Salut, salut,

Trop bien, je bouge en Ardèche demain moi :)

J'ai fait un support, fait rapidement avec l'inspi de Jah ^^
On se fait un appel en décembre pour les accès + discussion support ?

A bientôt,
Rob

[Support1Saggitarius.png][Support2Sadgitarius.png]

Envoyé avec la messagerie sécurisée [Proton Mail.](https://proton.me/mail/home)

Le jeudi 28 novembre 2024 à 21:34, Fred G1SMS <fred@g1sms.fr> a écrit :

> Salut Robin,
>
> Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la campagne.
> Me voila de retour à Toulouse, au G1FabLab.
>
> Le 22/11/2024 à 16:10, Robin Couret a écrit :
>
>> Salut Fred,
>>
>> C'était sympa de se rencontrer IRL !
>
> Ouaih! Cool de s'être rencontré au Capitole du Libre.
>
>> Je te propose une suite à nos échanges :
>>
>> - Le point départ c'est une volonté commune d'expérimenter sur des LLM open-source, avec des machines auto-hébergées.
>
> Oui! C'est ce qu'on va expérimenter ensemble ;)
> En ajoutant l'utilisation de jetons pour en gérer l'accès et en partager les ressources...
> J'en cause sur le blog de https://www.copylaradio.com/
>
>> - Pour les accès serveur on s'organise comment ?
>
> On pourra utiliser ssh en visio pour commencer. Et puis détailler ce qu'il te faut comme
> ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>
>> - Je peux contribuer via le système d'abonnement à 15-20e par mois.
>
> Tu peux prendre un forfait "COOL",
> https://opencollective.com/uplanet-zero/contribute/
> ou cotiser à l'Infrastructure "G1FabLab Toulouse"
> https://opencollective.com/monnaie-libre
>
>> - Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>
> Je touche un peu à tout, mais oui, j'adore les système résilients autonomes ;)
>
>> -
>>
>> De mon côté c'est les interactions humain-réseau de neurone que je souhaite explorer.
>> Je te partage la maquette de mon gestionnaire de prompt ;)
>
> Tu me diras ce qu'il faut pout exécuter son code ?
> API ollama, librairies python, docker ou autre...
>
>> [promptyx-ui-0.1.png]
>>
>> A bientôt,
>> Robin

Réponse générée : 
Je t'ai envoyé un lien si tu veux participer à la rédaction d'articles 
sur www.copylaradio.com

Le 28/11/2024 à 22:02, Robin Couret a écrit :
> Salut, salut,
>
> Trop bien, je bouge en Ardèche demain moi :)
>
> J'ai fait un support, fait rapidement avec l'inspi de Jah ^^
> On se fait un appel en décembre pour les accès + discussion support ?
>
> A bientôt,
> Rob
>
> Support1Saggitarius.pngSupport2Sadgitarius.png
>
> Envoyé avec la messagerie sécurisée Proton Mail. 
> <https://proton.me/mail/home>
>
> Le jeudi 28 novembre 2024 à 21:34, Fred G1SMS <fred@g1sms.fr> a écrit :
>>
>> Salut Robin,
>>
>> Je reviens d'un petit tour en Ariège pour prendre un peu l'air à la 
>> campagne.
>> Me voila de retour à Toulouse, au G1FabLab.
>>
>> Le 22/11/2024 à 16:10, Robin Couret a écrit :
>>> Salut Fred,
>>>
>>> C'était sympa de se rencontrer IRL !
>> Ouaih! Cool de s'être rencontré au Capitole du Libre.
>>>
>>> Je te propose une suite à nos échanges :
>>>
>>>   * Le point départ c'est une volonté commune d'expérimenter sur des
>>>     LLM open-source, avec des machines auto-hébergées.
>>>
>> Oui! C'est ce qu'on va expérimenter ensemble ;)
>> En ajoutant l'utilisation de jetons pour en gérer l'accès et en 
>> partager les ressources...
>> J'en cause sur le blog de https://www.copylaradio.com/
>>>
>>>   * Pour les accès serveur on s'organise comment ?
>>>
>> On pourra utiliser ssh en visio pour commencer. Et puis détailler ce 
>> qu'il te faut comme
>> ensuite, on se reliera en essaim privé ipfs pour "forwarder les ports"
>>>
>>>   * Je peux contribuer via le système d'abonnement à 15-20e par mois.
>>>
>> Tu peux prendre un forfait "COOL",
>> https://opencollective.com/uplanet-zero/contribute/
>> ou cotiser à l'Infrastructure "G1FabLab Toulouse"
>> https://opencollective.com/monnaie-libre
>>
>>>   * Ton expertise c'est l'infrastructure et les systèmes décentralisés ?
>>>
>> Je touche un peu à tout, mais oui, j'adore les système résilients 
>> autonomes ;)
>>
>>>  *
>>>
>>>
>>> De mon côté c'est les interactions humain-réseau de neurone que je 
>>> souhaite explorer.
>>> Je te partage la maquette de mon gestionnaire de prompt ;)
>> Tu me diras ce qu'il faut pout exécuter son code ?
>> API ollama, librairies python, docker ou autre...
>>
>>>
>>> promptyx-ui-0.1.png
>>>
>>> A bientôt,
>>> Robin
>